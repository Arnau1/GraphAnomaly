{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import torch.utils.data as data \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.nn import MessagePassing, SAGEConv\n",
    "from ogb.nodeproppred import Evaluator #PygNodePropPredDatase\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/gsamp/OneDrive/Documents/AI-3/2n Semestre/Projecte de Síntesi 2/GraphAnomaly/dades_guillem/\"\n",
    "df_classes = pd.read_csv(path + \"elliptic_txs_classes.csv\") # Nodes' labels\n",
    "df_edges_init = pd.read_csv(path + \"elliptic_txs_edgelist.csv\") # Edges\n",
    "df_features = pd.read_csv(path + \"elliptic_txs_features.csv\", header=None) # Nodes' features\n",
    "\n",
    "# Change column names of df_features\n",
    "colNames1 = {'0': 'txId', 1: \"Time step\"}\n",
    "colNames2 = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(93)}\n",
    "colNames3 = {str(ii+95): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n",
    "\n",
    "colNames = dict(colNames1, **colNames2, **colNames3 )\n",
    "colNames = {int(jj): item_kk for jj,item_kk in colNames.items()}\n",
    "\n",
    "df_features = df_features.rename(columns=colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your pickle file\n",
    "pickle_file_path = 'C:\\\\Users\\\\gsamp\\\\OneDrive\\\\Documents\\\\AI-3\\\\2n Semestre\\\\Projecte de Síntesi 2\\\\GraphAnomaly\\\\elipticData_graph.pkl'\n",
    "\n",
    "# Open the pickle file in binary mode\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    # Load the data from the pickle file\n",
    "    G = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsamp\\AppData\\Local\\Temp\\ipykernel_12932\\183557646.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged['class'] = df_merged['class'].replace(class_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234355, 2)\n",
      "(36624, 2)\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(left=df_features, right=df_classes, on=\"txId\", how=\"left\")\n",
    "df_merged = df_merged.set_index('txId')\n",
    "\n",
    "class_mapping = {'unknown': 2, '1':0, '2':1}\n",
    "df_merged['class'] = df_merged['class'].replace(class_mapping)\n",
    "\n",
    "df_merged = df_merged.reset_index()\n",
    "\n",
    "df_merged = df_merged.loc[df_merged['class'].isin([0,1])]\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "print(df_edges_init.shape)\n",
    "df_edges = df_edges_init.loc[((df_edges_init['txId1'].isin(df_merged['txId'])) & (df_edges_init['txId2'].isin(df_merged['txId'])))]\n",
    "df_edges = df_edges.reset_index(drop=True)\n",
    "print(df_edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_txid = dict(zip(df_merged['txId'], list(df_merged.index)))\n",
    "\n",
    "m = True\n",
    "if m:\n",
    "    df_edges_mapped = df_edges.replace({'txId1': mapping_txid, 'txId2': mapping_txid})\n",
    "    df_edges_mapped.to_pickle('dades_guillem\\mapped_edges.pkl')\n",
    "else:\n",
    "    df_edges_mapped = pd.read_pickle('dades_guillem\\mapped_edges.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df_merged.drop(columns=['class', 'Time step']).values, dtype=torch.float)\n",
    "edge_index = torch.tensor(df_edges_mapped.values, dtype=torch.long).T\n",
    "y = torch.tensor(df_merged['class'].values)\n",
    "time = torch.tensor(df_merged['Time step'].values)\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y, time=time)\n",
    "\n",
    "\n",
    "test_size = 0.2  # 20% of the data will be in the test set\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_idx, test_idx = train_test_split(range(len(y)), test_size=test_size, random_state=42)\n",
    "\n",
    "# Create train and test masks\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for the AE case\n",
    "\n",
    "#separate illicit and licit data\n",
    "licit_x = torch.tensor(df_merged.loc[df_merged['class'] == 1].drop(columns=['class', 'Time step']).values, dtype=torch.float)\n",
    "licit_y = torch.tensor(df_merged.loc[df_merged['class'] == 1]['class'].values)\n",
    "licit_data = Data(x=licit_x, y=licit_y)\n",
    "\n",
    "illicit_x = torch.tensor(df_merged.loc[df_merged['class'] == 0].drop(columns=['class', 'Time step']).values, dtype=torch.float)\n",
    "illicit_y = torch.tensor(df_merged.loc[df_merged['class'] == 0]['class'].values)\n",
    "illicit_data = Data(x=illicit_x, y=illicit_x)\n",
    "\n",
    "#prepare train/test split oly with the licit data which will be used to train the AE\n",
    "test_size = 0.2\n",
    "#the real target of the AE won't be the y però aquí només ens importa el tamany (xd)\n",
    "train_idx, test_idx = train_test_split(range(len(licit_y)), test_size=test_size, random_state=42)\n",
    "\n",
    "# Create train and test masks\n",
    "train_mask = torch.zeros(len(licit_y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(licit_y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "#declarar-los com a mètodes per fer-ho més còmode\n",
    "licit_data.train_mask = train_mask\n",
    "licit_data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return torch.tensor(sample, dtype=torch.float32), torch.tensor(sample, dtype=torch.float32)\n",
    "\n",
    "# # Define batch size\n",
    "# batch_size = 64\n",
    "# sampling_idxs = torch.randperm(licit_data.x.size(0))[:2000]\n",
    "# dataset = CustomDataset(licit_data.x[sampling_idxs])\n",
    "# data_loader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=50):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100, input_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(autoencoder, data_loader, criterion, optimizer, val_loader, num_epochs=10, learning_rate=0.001):   \n",
    "    total_train_loss = [] \n",
    "    total_validation_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = autoencoder(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss = running_loss / len(data_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}\")\n",
    "        validation_loss = val_ae(autoencoder=autoencoder, data_loader=val_loader, criterion=criterion)\n",
    "        print(f\"Validation Loss: {validation_loss:.4f}\")\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_validation_loss.append(validation_loss)\n",
    "    return total_train_loss, total_validation_loss\n",
    "\n",
    "def val_ae(autoencoder, data_loader, criterion):\n",
    "    autoencoder.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = autoencoder(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = val_loss / len(data_loader.dataset)\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.1430\n",
      "Validation Loss: 0.1411\n",
      "Epoch [2/50], Training Loss: 0.1430\n",
      "Validation Loss: 0.1411\n",
      "Epoch [3/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1411\n",
      "Epoch [4/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1411\n",
      "Epoch [5/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1411\n",
      "Epoch [6/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [7/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [8/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [9/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [10/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [11/50], Training Loss: 0.1429\n",
      "Validation Loss: 0.1410\n",
      "Epoch [12/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1410\n",
      "Epoch [13/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1410\n",
      "Epoch [14/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1410\n",
      "Epoch [15/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1409\n",
      "Epoch [16/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1409\n",
      "Epoch [17/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1409\n",
      "Epoch [18/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1409\n",
      "Epoch [19/50], Training Loss: 0.1428\n",
      "Validation Loss: 0.1409\n",
      "Epoch [20/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1409\n",
      "Epoch [21/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1409\n",
      "Epoch [22/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1409\n",
      "Epoch [23/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1408\n",
      "Epoch [24/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1408\n",
      "Epoch [25/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1408\n",
      "Epoch [26/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1408\n",
      "Epoch [27/50], Training Loss: 0.1427\n",
      "Validation Loss: 0.1408\n",
      "Epoch [28/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1408\n",
      "Epoch [29/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1408\n",
      "Epoch [30/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1408\n",
      "Epoch [31/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1407\n",
      "Epoch [32/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1407\n",
      "Epoch [33/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1407\n",
      "Epoch [34/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1407\n",
      "Epoch [35/50], Training Loss: 0.1426\n",
      "Validation Loss: 0.1407\n",
      "Epoch [36/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1407\n",
      "Epoch [37/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1407\n",
      "Epoch [38/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1407\n",
      "Epoch [39/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1406\n",
      "Epoch [40/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1406\n",
      "Epoch [41/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1406\n",
      "Epoch [42/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1406\n",
      "Epoch [43/50], Training Loss: 0.1425\n",
      "Validation Loss: 0.1406\n",
      "Epoch [44/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1406\n",
      "Epoch [45/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1406\n",
      "Epoch [46/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1405\n",
      "Epoch [47/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1405\n",
      "Epoch [48/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1405\n",
      "Epoch [49/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1405\n",
      "Epoch [50/50], Training Loss: 0.1424\n",
      "Validation Loss: 0.1405\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "n= 2000\n",
    "#samplejar només n elements de les lícites per entrenar el AE\n",
    "x = torch.tensor(df_merged.loc[df_merged[\"class\"] == 1].drop(columns=['class', 'txId', 'Time step'])[:n].values)\n",
    "#amb el scaler la loss passe de 4 a 0.1\n",
    "x = preprocessing.MinMaxScaler().fit_transform(x)\n",
    "\n",
    "train_data, val_data = train_test_split(x, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = CustomDataset(val_data)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#hiperparàmetres\n",
    "lr = 0.001\n",
    "EPOCHS = 50\n",
    "\n",
    "input_dim = x.shape[1]\n",
    "model = Autoencoder(input_dim)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "training_loss, validation_loss = train_ae(autoencoder=model, data_loader=train_loader, criterion=criterion, optimizer=optimizer, val_loader=val_loader, num_epochs=EPOCHS, learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model for inference\n",
    "def load_model(path: str):\n",
    "    loaded_model = Autoencoder(input_dim=input_dim)\n",
    "    loaded_model.load_state_dict(torch.load(path))\n",
    "    loaded_model.eval()\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsamp\\AppData\\Local\\Temp\\ipykernel_12932\\3507107447.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sample, dtype=torch.float32), torch.tensor(sample, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'AE_models/AE1.pth')\n",
    "\n",
    "loaded_model = load_model('AE_models/AE1.pth')\n",
    "ilicit = torch.tensor(df_merged.loc[df_merged['class'] == 0].drop(columns=['class', 'Time step', 'txId']).values, dtype=torch.float)\n",
    "ilicit_data = CustomDataset(ilicit)\n",
    "ilicit_loader = DataLoader(ilicit_data, shuffle=True)\n",
    "\n",
    "reconstruction_loss = []\n",
    "for inputs, targets in ilicit_loader:\n",
    "    out = loaded_model(inputs)\n",
    "    loss = criterion(out, targets)\n",
    "    epoch_loss = loss.item() * inputs.size(0)\n",
    "    reconstruction_loss.append(epoch_loss)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBTAIN THE LATENT REPRESENTATION OF THE AUTOENCODER\n",
    "\n",
    "més fàcil que això simplement enxufar les daded a loaded_model.encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m x_fraud_tensor \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mMinMaxScaler()\u001b[38;5;241m.\u001b[39mfit_transform(x_fraud)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     norm_hid_rep \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_norm_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     fraud_hid_rep \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mencoder(x_fraud_tensor)\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "#get only licit cases\n",
    "x_norm = torch.tensor(df_merged.loc[df_merged['class'] == 0].drop(columns=[\"class\", \"txId\", \"Time step\"]).values)\n",
    "#scale\n",
    "x_norm = preprocessing.MinMaxScaler().fit_transform(x_norm)\n",
    "# Generate random indices\n",
    "indices = torch.randperm(len(x_norm))[:4000]\n",
    "# Sample elements using random indices\n",
    "x_norm_tensor = x_norm[indices]\n",
    "\n",
    "#get fraud cases\n",
    "x_fraud = torch.tensor(df_merged.loc[df_merged['class'] == 1].drop(columns=[\"class\", \"txId\", \"Time step\"]).values)\n",
    "#scale\n",
    "x_fraud_tensor = preprocessing.MinMaxScaler().fit_transform(x_fraud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    norm_hid_rep = loaded_model.encoder(torch.tensor(x_norm_tensor[:4000]))\n",
    "    fraud_hid_rep = loaded_model.encoder(x_fraud_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsamp\\AppData\\Local\\Temp\\ipykernel_11488\\3507107447.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sample, dtype=torch.float32), torch.tensor(sample, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent space representations shape: torch.Size([4000, 50])\n",
      "Latent space representations shape: torch.Size([4000, 50])\n"
     ]
    }
   ],
   "source": [
    "# Obtain latent space representation\n",
    "\n",
    "#get only licit cases\n",
    "x_norm = torch.tensor(df_merged.loc[df_merged['class'] == 0].drop(columns=[\"class\", \"txId\", \"Time step\"]).values)\n",
    "#scale\n",
    "x_norm = preprocessing.MinMaxScaler().fit_transform(x_norm)\n",
    "# Generate random indices\n",
    "indices = torch.randperm(len(x_norm))[:4000]\n",
    "# Sample elements using random indices\n",
    "x_norm_tensor = x_norm[indices]\n",
    "\n",
    "latent_data = CustomDataset(x_norm_tensor)\n",
    "latent_loader = DataLoader(latent_data, shuffle=True)\n",
    "licit_latent_representation  = []\n",
    "fraud_latent_representation = []\n",
    "with torch.no_grad():\n",
    "    for licit_data, fraud_data in zip(latent_loader, ilicit_loader):\n",
    "        #obtain the representation for the licit data\n",
    "        inputs, _ = licit_data\n",
    "        # inputs = inputs.view(inputs.size(0), -1)\n",
    "        latent = loaded_model.encoder(inputs)\n",
    "        licit_latent_representation.append(latent)\n",
    "        \n",
    "        #obtain the representation for the fraud data\n",
    "        inputs, _ = fraud_data\n",
    "        # inputs = inputs.view(inputs.size(0), -1)\n",
    "        latent = loaded_model.encoder(inputs)\n",
    "        fraud_latent_representation.append(latent)\n",
    "        \n",
    "\n",
    "norm_hid_rep= torch.cat(licit_latent_representation, dim=0)\n",
    "print(\"Latent space representations shape:\", norm_hid_rep.shape)\n",
    "\n",
    "\n",
    "fraud_hid_rep = torch.cat(fraud_latent_representation, dim=0)\n",
    "print(\"Latent space representations shape:\", fraud_hid_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mumap_plot\u001b[39m(data, labels, save_path):\n\u001b[0;32m      4\u001b[0m     umap_data \u001b[38;5;241m=\u001b[39m umap\u001b[38;5;241m.\u001b[39mUMAP(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(data)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "def umap_plot(data, labels, save_path):\n",
    "    umap_data = umap.UMAP(n_components=2, random_state=42).fit_transform(data)\n",
    "    sns.scatterplot(x=umap_data[:, 0], y=umap_data[:, 1], hue=labels)\n",
    "    plt.xlabel('UMAP component 1')\n",
    "    plt.ylabel('UMAP component 2')\n",
    "    plt.title('UMAP Plot')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-97 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 16: invalid start byte\n",
      "c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m y_f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(fraud_hid_rep\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m rep_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_n, y_f)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtsne_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_representation.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m, in \u001b[0;36mtsne_plot\u001b[1;34m(data, labels, save_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtsne_plot\u001b[39m(data, labels, save_path):\n\u001b[0;32m      3\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     tsne_data \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mscatter(tsne_data[:, \u001b[38;5;241m0\u001b[39m], tsne_data[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt-SNE component 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1136\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \n\u001b[0;32m   1117\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1136\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1026\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1094\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m   1093\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter_without_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_without_progress\n\u001b[1;32m-> 1094\u001b[0m     params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;66;03m# Save the final number of iterations\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m it\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:402\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[1;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[0;32m    400\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m n_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 402\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    405\u001b[0m dec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minvert(inc)\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:283\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[0;32m    280\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    282\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 283\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[43m_barnes_hut_tsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m (degrees_of_freedom \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m degrees_of_freedom\n\u001b[0;32m    297\u001b[0m grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis=0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "\n",
    "# Call umap_plot function\n",
    "umap_plot(rep_x, rep_y, \"latent_representation.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
