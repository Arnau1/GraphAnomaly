{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.nn import MessagePassing, SAGEConv\n",
    "from ogb.nodeproppred import Evaluator #PygNodePropPredDatase\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/gsamp/OneDrive/Documents/AI-3/2n Semestre/Projecte de Síntesi 2/GraphAnomaly/dades_guillem/\"\n",
    "df_classes = pd.read_csv(path + \"elliptic_txs_classes.csv\") # Nodes' labels\n",
    "df_edges_init = pd.read_csv(path + \"elliptic_txs_edgelist.csv\") # Edges\n",
    "df_features = pd.read_csv(path + \"elliptic_txs_features.csv\", header=None) # Nodes' features\n",
    "\n",
    "# Change column names of df_features\n",
    "colNames1 = {'0': 'txId', 1: \"Time step\"}\n",
    "colNames2 = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(93)}\n",
    "colNames3 = {str(ii+95): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n",
    "\n",
    "colNames = dict(colNames1, **colNames2, **colNames3 )\n",
    "colNames = {int(jj): item_kk for jj,item_kk in colNames.items()}\n",
    "\n",
    "df_features = df_features.rename(columns=colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your pickle file\n",
    "pickle_file_path = 'C:\\\\Users\\\\gsamp\\\\OneDrive\\\\Documents\\\\AI-3\\\\2n Semestre\\\\Projecte de Síntesi 2\\\\GraphAnomaly\\\\elipticData_graph.pkl'\n",
    "\n",
    "# Open the pickle file in binary mode\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    # Load the data from the pickle file\n",
    "    G = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsamp\\AppData\\Local\\Temp\\ipykernel_19956\\183557646.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_merged['class'] = df_merged['class'].replace(class_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234355, 2)\n",
      "(36624, 2)\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(left=df_features, right=df_classes, on=\"txId\", how=\"left\")\n",
    "df_merged = df_merged.set_index('txId')\n",
    "\n",
    "class_mapping = {'unknown': 2, '1':0, '2':1}\n",
    "df_merged['class'] = df_merged['class'].replace(class_mapping)\n",
    "\n",
    "df_merged = df_merged.reset_index()\n",
    "\n",
    "df_merged = df_merged.loc[df_merged['class'].isin([0,1])]\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "print(df_edges_init.shape)\n",
    "df_edges = df_edges_init.loc[((df_edges_init['txId1'].isin(df_merged['txId'])) & (df_edges_init['txId2'].isin(df_merged['txId'])))]\n",
    "df_edges = df_edges.reset_index(drop=True)\n",
    "print(df_edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aquest mapping es farà servir per saber de quin node es tracta i poder mirar si hia ha\n",
    "#errors a l'hora de generar edges i tot això\n",
    "mapping_txid = dict(zip(df_merged['txId'], list(df_merged.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = True\n",
    "if m:\n",
    "    df_edges_mapped = df_edges.replace({'txId1': mapping_txid, 'txId2': mapping_txid})\n",
    "    df_edges_mapped.to_pickle('dades_guillem\\mapped_edges.pkl')\n",
    "else:\n",
    "    df_edges_mapped = pd.read_pickle('dades_guillem\\mapped_edges.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df_merged.drop(columns=['class', 'Time step']).values, dtype=torch.float)\n",
    "edge_index = torch.tensor(df_edges_mapped.values, dtype=torch.long).T\n",
    "y = torch.tensor(df_merged['class'].values)\n",
    "time = torch.tensor(df_merged['Time step'].values)\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y, time=time)\n",
    "\n",
    "\n",
    "test_size = 0.2  # 20% of the data will be in the test set\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_idx, test_idx = train_test_split(range(len(y)), test_size=test_size, random_state=42)\n",
    "\n",
    "# Create train and test masks\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no es fa servir\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, x, edge_index, y, time):\n",
    "        self.x = x\n",
    "        self.edge_index = edge_index\n",
    "        self.y = y\n",
    "        self.time = time\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.x[idx],\n",
    "            'edge_index': self.edge_index[idx],\n",
    "            'y': self.y[idx],\n",
    "            'time': self.time[idx]\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(166, 4)\n",
      "  (conv2): GCNConv(4, 8)\n",
      "  (conv3): GCNConv(8, 16)\n",
      "  (conv4): GCNConv(16, 8)\n",
      "  (conv5): GCNConv(8, 4)\n",
      "  (conv6): GCNConv(4, 2)\n",
      "  (classifier): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(data.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 8)\n",
    "        self.conv3 = GCNConv(8, 16)\n",
    "        self.conv4 = GCNConv(16, 8)\n",
    "        self.conv5 = GCNConv(8, 4)\n",
    "        self.conv6 = GCNConv(4, 2)\n",
    "        num_classes = torch.unique(data.y).size(0)\n",
    "        self.classifier = Linear(2, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        h = self.conv4(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv5(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv6(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.45057836174964905, Test Loss: 0.37349194288253784\n",
      "Epoch: 1, Loss: 0.3750728666782379, Test Loss: 0.35563361644744873\n",
      "Epoch: 2, Loss: 0.35744771361351013, Test Loss: 0.34769299626350403\n",
      "Epoch: 3, Loss: 0.3496260643005371, Test Loss: 0.3420492112636566\n",
      "Epoch: 4, Loss: 0.3440730571746826, Test Loss: 0.33738812804222107\n",
      "Epoch: 5, Loss: 0.3394941985607147, Test Loss: 0.3333880603313446\n",
      "Epoch: 6, Loss: 0.3355734348297119, Test Loss: 0.3299364745616913\n",
      "Epoch: 7, Loss: 0.3321998417377472, Test Loss: 0.32697683572769165\n",
      "Epoch: 8, Loss: 0.32931727170944214, Test Loss: 0.32447096705436707\n",
      "Epoch: 9, Loss: 0.3268873393535614, Test Loss: 0.32238635420799255\n",
      "Epoch: 10, Loss: 0.32487723231315613, Test Loss: 0.32069242000579834\n",
      "Epoch: 11, Loss: 0.3232560157775879, Test Loss: 0.31935691833496094\n",
      "Epoch: 12, Loss: 0.32199111580848694, Test Loss: 0.3183455467224121\n",
      "Epoch: 13, Loss: 0.3210475742816925, Test Loss: 0.3176213204860687\n",
      "Epoch: 14, Loss: 0.32038798928260803, Test Loss: 0.31714481115341187\n",
      "Epoch: 15, Loss: 0.31997260451316833, Test Loss: 0.3168753981590271\n",
      "Epoch: 16, Loss: 0.3197602927684784, Test Loss: 0.3167722523212433\n",
      "Epoch: 17, Loss: 0.31970980763435364, Test Loss: 0.3167957365512848\n",
      "Epoch: 18, Loss: 0.3197811245918274, Test Loss: 0.3169085383415222\n",
      "Epoch: 19, Loss: 0.3199367821216583, Test Loss: 0.3170771598815918\n",
      "Epoch: 20, Loss: 0.3201429843902588, Test Loss: 0.31727251410484314\n",
      "Epoch: 21, Loss: 0.32037052512168884, Test Loss: 0.3174702823162079\n",
      "Epoch: 22, Loss: 0.32059523463249207, Test Loss: 0.3176518380641937\n",
      "Epoch: 23, Loss: 0.3207983076572418, Test Loss: 0.31780335307121277\n",
      "Epoch: 24, Loss: 0.32096627354621887, Test Loss: 0.3179159164428711\n",
      "Epoch: 25, Loss: 0.32109037041664124, Test Loss: 0.31798529624938965\n",
      "Epoch: 26, Loss: 0.3211665153503418, Test Loss: 0.3180105984210968\n",
      "Epoch: 27, Loss: 0.3211941719055176, Test Loss: 0.31799426674842834\n",
      "Epoch: 28, Loss: 0.3211762309074402, Test Loss: 0.31794095039367676\n",
      "Epoch: 29, Loss: 0.321117639541626, Test Loss: 0.3178569972515106\n",
      "Epoch: 30, Loss: 0.32102516293525696, Test Loss: 0.31774982810020447\n",
      "Epoch: 31, Loss: 0.3209066390991211, Test Loss: 0.3176271617412567\n",
      "Epoch: 32, Loss: 0.32077014446258545, Test Loss: 0.3174968361854553\n",
      "Epoch: 33, Loss: 0.3206240236759186, Test Loss: 0.3173660933971405\n",
      "Epoch: 34, Loss: 0.32047587633132935, Test Loss: 0.3172413110733032\n",
      "Epoch: 35, Loss: 0.32033246755599976, Test Loss: 0.31712788343429565\n",
      "Epoch: 36, Loss: 0.3201996684074402, Test Loss: 0.317029744386673\n",
      "Epoch: 37, Loss: 0.3200816512107849, Test Loss: 0.31694963574409485\n",
      "Epoch: 38, Loss: 0.3199816346168518, Test Loss: 0.3168887495994568\n",
      "Epoch: 39, Loss: 0.31990107893943787, Test Loss: 0.3168472349643707\n",
      "Epoch: 40, Loss: 0.31984037160873413, Test Loss: 0.3168238699436188\n",
      "Epoch: 41, Loss: 0.3197988271713257, Test Loss: 0.31681668758392334\n",
      "Epoch: 42, Loss: 0.319774329662323, Test Loss: 0.3168228268623352\n",
      "Epoch: 43, Loss: 0.31976446509361267, Test Loss: 0.3168392777442932\n",
      "Epoch: 44, Loss: 0.3197663426399231, Test Loss: 0.3168625235557556\n",
      "Epoch: 45, Loss: 0.3197766840457916, Test Loss: 0.31688958406448364\n",
      "Epoch: 46, Loss: 0.31979238986968994, Test Loss: 0.31691718101501465\n",
      "Epoch: 47, Loss: 0.31981033086776733, Test Loss: 0.31694284081459045\n",
      "Epoch: 48, Loss: 0.3198280334472656, Test Loss: 0.3169645071029663\n",
      "Epoch: 49, Loss: 0.3198435306549072, Test Loss: 0.31698077917099\n",
      "Epoch: 50, Loss: 0.3198552429676056, Test Loss: 0.3169907331466675\n",
      "Epoch: 51, Loss: 0.3198622763156891, Test Loss: 0.31699395179748535\n",
      "Epoch: 52, Loss: 0.3198641240596771, Test Loss: 0.31699079275131226\n",
      "Epoch: 53, Loss: 0.3198610246181488, Test Loss: 0.31698164343833923\n",
      "Epoch: 54, Loss: 0.31985318660736084, Test Loss: 0.31696760654449463\n",
      "Epoch: 55, Loss: 0.3198416829109192, Test Loss: 0.31694963574409485\n",
      "Epoch: 56, Loss: 0.31982725858688354, Test Loss: 0.3169289827346802\n",
      "Epoch: 57, Loss: 0.3198109567165375, Test Loss: 0.3169068396091461\n",
      "Epoch: 58, Loss: 0.3197939395904541, Test Loss: 0.31688418984413147\n",
      "Epoch: 59, Loss: 0.3197769224643707, Test Loss: 0.31686222553253174\n",
      "Epoch: 60, Loss: 0.3197610378265381, Test Loss: 0.31684157252311707\n",
      "Epoch: 61, Loss: 0.31974664330482483, Test Loss: 0.31682276725769043\n",
      "Epoch: 62, Loss: 0.3197340965270996, Test Loss: 0.3168061673641205\n",
      "Epoch: 63, Loss: 0.3197237551212311, Test Loss: 0.3167920410633087\n",
      "Epoch: 64, Loss: 0.3197157084941864, Test Loss: 0.3167801797389984\n",
      "Epoch: 65, Loss: 0.3197095990180969, Test Loss: 0.3167704939842224\n",
      "Epoch: 66, Loss: 0.31970521807670593, Test Loss: 0.31676262617111206\n",
      "Epoch: 67, Loss: 0.31970202922821045, Test Loss: 0.3167561888694763\n",
      "Epoch: 68, Loss: 0.31969985365867615, Test Loss: 0.31675103306770325\n",
      "Epoch: 69, Loss: 0.31969818472862244, Test Loss: 0.3167465329170227\n",
      "Epoch: 70, Loss: 0.31969666481018066, Test Loss: 0.3167424201965332\n",
      "Epoch: 71, Loss: 0.31969472765922546, Test Loss: 0.31673866510391235\n",
      "Epoch: 72, Loss: 0.3196924924850464, Test Loss: 0.31673479080200195\n",
      "Epoch: 73, Loss: 0.31968948245048523, Test Loss: 0.31673091650009155\n",
      "Epoch: 74, Loss: 0.3196857273578644, Test Loss: 0.316726952791214\n",
      "Epoch: 75, Loss: 0.319681316614151, Test Loss: 0.3167228698730469\n",
      "Epoch: 76, Loss: 0.3196762800216675, Test Loss: 0.3167186677455902\n",
      "Epoch: 77, Loss: 0.31967058777809143, Test Loss: 0.3167145848274231\n",
      "Epoch: 78, Loss: 0.3196645677089691, Test Loss: 0.31671062111854553\n",
      "Epoch: 79, Loss: 0.3196583688259125, Test Loss: 0.3167067766189575\n",
      "Epoch: 80, Loss: 0.3196520507335663, Test Loss: 0.31670334935188293\n",
      "Epoch: 81, Loss: 0.31964588165283203, Test Loss: 0.31670019030570984\n",
      "Epoch: 82, Loss: 0.3196399509906769, Test Loss: 0.31669723987579346\n",
      "Epoch: 83, Loss: 0.3196340799331665, Test Loss: 0.3166946470737457\n",
      "Epoch: 84, Loss: 0.31962865591049194, Test Loss: 0.3166922628879547\n",
      "Epoch: 85, Loss: 0.31962350010871887, Test Loss: 0.31668993830680847\n",
      "Epoch: 86, Loss: 0.3196185827255249, Test Loss: 0.31668761372566223\n",
      "Epoch: 87, Loss: 0.31961384415626526, Test Loss: 0.31668519973754883\n",
      "Epoch: 88, Loss: 0.31960922479629517, Test Loss: 0.31668251752853394\n",
      "Epoch: 89, Loss: 0.31960466504096985, Test Loss: 0.3166794776916504\n",
      "Epoch: 90, Loss: 0.31960004568099976, Test Loss: 0.3166760802268982\n",
      "Epoch: 91, Loss: 0.3195953369140625, Test Loss: 0.3166722059249878\n",
      "Epoch: 92, Loss: 0.3195904493331909, Test Loss: 0.3166678547859192\n",
      "Epoch: 93, Loss: 0.319585382938385, Test Loss: 0.31666305661201477\n",
      "Epoch: 94, Loss: 0.3195801079273224, Test Loss: 0.3166577219963074\n",
      "Epoch: 95, Loss: 0.31957462430000305, Test Loss: 0.31665199995040894\n",
      "Epoch: 96, Loss: 0.31956902146339417, Test Loss: 0.31664592027664185\n",
      "Epoch: 97, Loss: 0.31956321001052856, Test Loss: 0.3166395425796509\n",
      "Epoch: 98, Loss: 0.3195573389530182, Test Loss: 0.3166329562664032\n",
      "Epoch: 99, Loss: 0.3195513188838959, Test Loss: 0.3166262209415436\n",
      "Epoch: 100, Loss: 0.3195452392101288, Test Loss: 0.3166194260120392\n",
      "Epoch: 101, Loss: 0.31953921914100647, Test Loss: 0.3166125416755676\n",
      "Epoch: 102, Loss: 0.3195330500602722, Test Loss: 0.31660568714141846\n",
      "Epoch: 103, Loss: 0.31952694058418274, Test Loss: 0.31659889221191406\n",
      "Epoch: 104, Loss: 0.3195207715034485, Test Loss: 0.31659212708473206\n",
      "Epoch: 105, Loss: 0.31951460242271423, Test Loss: 0.3165854215621948\n",
      "Epoch: 106, Loss: 0.3195083439350128, Test Loss: 0.31657886505126953\n",
      "Epoch: 107, Loss: 0.319502055644989, Test Loss: 0.316572368144989\n",
      "Epoch: 108, Loss: 0.3194957375526428, Test Loss: 0.31656578183174133\n",
      "Epoch: 109, Loss: 0.31948918104171753, Test Loss: 0.3165593147277832\n",
      "Epoch: 110, Loss: 0.3194826543331146, Test Loss: 0.31655293703079224\n",
      "Epoch: 111, Loss: 0.3194758892059326, Test Loss: 0.3165464997291565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m400\u001b[39m):\n\u001b[0;32m     34\u001b[0m     loss, h, out \u001b[38;5;241m=\u001b[39m train(data)\n\u001b[1;32m---> 35\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[137], line 16\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient computation since we are in evaluation mode.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform a forward pass.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out[data\u001b[38;5;241m.\u001b[39mtest_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtest_mask])\n\u001b[0;32m     19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Get the predicted labels by selecting the class with the highest probability.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[108], line 19\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     17\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(h, edge_index)\n\u001b[0;32m     18\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtanh()\n\u001b[1;32m---> 19\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtanh()  \u001b[38;5;66;03m# Final GNN embedding space.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(h, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:538\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[0;32m    536\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[1;32m--> 538\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mcollect_param_data(\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:400\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    399\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[1;32m--> 400\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:360\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    358\u001b[0m         index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m    363\u001b[0m     row, col, _ \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mcoo()\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:306\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gsamp\\anaconda3\\envs\\visionEnv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:310\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "criterion = torch.nn.CrossEntropyLoss()  #Initialize the CrossEntropyLoss function.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Initialize the Adam optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h, out\n",
    "\n",
    "def test(data):\n",
    "    model.eval()  # Set the model to evaluation mode.\n",
    "    with torch.no_grad():  # Disable gradient computation since we are in evaluation mode.\n",
    "        out, _ = model(data.x, data.edge_index)  # Perform a forward pass.\n",
    "        loss = criterion(out[data.test_mask], data.y[data.test_mask])\n",
    "        \n",
    "        pred = out.argmax(dim=1)  # Get the predicted labels by selecting the class with the highest probability.\n",
    "        # print(pred)\n",
    "        max_value = torch.max(pred)\n",
    "\n",
    "        counts = torch.bincount(pred, minlength=max_value.item() + 1)\n",
    "\n",
    "        # # Print the counts\n",
    "        # for i, count in enumerate(counts):\n",
    "        #     print(f\"Element {i} appears {count} times.\")\n",
    "        # correct = pred[data.test_mask] == data.y[data.test_mask]  # Compare predicted labels with true labels for test nodes.\n",
    "        # test_acc = correct.sum().item() / data.test_mask.sum().item()  # Calculate accuracy.\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(400):\n",
    "    loss, h, out = train(data)\n",
    "    test_loss = test(data)\n",
    "    print(f'Epoch: {epoch}, Loss: {loss}, Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels,\n",
    "                 hidden_channels, out_channels,\n",
    "                 n_layers=2):\n",
    "        \n",
    "        super(SAGE, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers_bn = torch.nn.ModuleList()\n",
    "        if n_layers == 1:\n",
    "            self.layers.append(SAGEConv(in_channels, out_channels,   normalize=False))\n",
    "        elif n_layers == 2:\n",
    "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
    "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
    "        else:\n",
    "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
    "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.layers.append(SAGEConv(hidden_channels,  hidden_channels, normalize=False))\n",
    "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
    "            \n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "            \n",
    "    def forward(self, x, edge_index):\n",
    "        if len(self.layers) > 1:\n",
    "            looper = self.layers[:-1]\n",
    "        else:\n",
    "            looper = self.layers\n",
    "        \n",
    "        for i, layer in enumerate(looper):\n",
    "            x = layer(x, edge_index)\n",
    "            try:\n",
    "                x = self.layers_bn[i](x)\n",
    "            except Exception as e:\n",
    "                abs(1)\n",
    "            finally:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        if len(self.layers) > 1:\n",
    "            x = self.layers[-1](x, edge_index)\n",
    "        return F.log_softmax(x, dim=-1), torch.var(x)\n",
    "    \n",
    "    def inference(self, total_loader, device):\n",
    "        xs = []\n",
    "        var_ = []\n",
    "        for batch in total_loader:\n",
    "            out, var = self.forward(batch.x.to(device), batch.edge_index.to(device))\n",
    "            out = out[:batch.batch_size]\n",
    "            xs.append(out.cpu())\n",
    "            var_.append(var.item())\n",
    "        \n",
    "        out_all = torch.cat(xs, dim=0)\n",
    "        \n",
    "        return out_all, var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    42019\n",
       "0     4545\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22601, 23963])\n",
      "Epoch: 0, \n",
      "              Training Loss: 0.7915518879890442, Training Accuracy: 0.5081205873667821\n",
      "              Test Loss: 4.151186466217041, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([  524, 46040])\n",
      "Epoch: 5, \n",
      "              Training Loss: 0.7586606740951538, Training Accuracy: 0.8924861077554965\n",
      "              Test Loss: 0.5787362456321716, Test Accuracy: 0.9028240094491571 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 10, \n",
      "              Training Loss: 0.37201619148254395, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.37844356894493103, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([  331, 46233])\n",
      "Epoch: 15, \n",
      "              Training Loss: 0.3776194155216217, Training Accuracy: 0.8982577648922176\n",
      "              Test Loss: 0.3142956793308258, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 20, \n",
      "              Training Loss: 0.31888559460639954, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.3150686025619507, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 25, \n",
      "              Training Loss: 0.31416183710098267, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.3096926212310791, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 30, \n",
      "              Training Loss: 0.3165886104106903, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.30822423100471497, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 35, \n",
      "              Training Loss: 0.3103131949901581, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.30833888053894043, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 40, \n",
      "              Training Loss: 0.31043827533721924, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.30956459045410156, Test Accuracy: 0.9034682701599914 \n",
      "              \n",
      "tensor([    0, 46564])\n",
      "Epoch: 45, \n",
      "              Training Loss: 0.3089924454689026, Training Accuracy: 0.902123432927975\n",
      "              Test Loss: 0.3064853549003601, Test Accuracy: 0.9034682701599914 \n",
      "              \n"
     ]
    }
   ],
   "source": [
    "model = SAGE(data.x.shape[1], 256, torch.unique(data.y).size(0), n_layers=2)\n",
    "epochs = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=7)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data, epoch):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    pred = out.argmax(dim=1)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = pred[data.train_mask].eq(data.y[data.train_mask]).sum().item()\n",
    "    total = data.train_mask.sum().item()\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        max_value = torch.max(pred)\n",
    "        counts = torch.bincount(pred, minlength=max_value.item() + 1)\n",
    "        print(counts)\n",
    "        \n",
    "    return loss, accuracy\n",
    "\n",
    "def test(data, epoch):\n",
    "    model.eval()  # Set the model to evaluation mode.\n",
    "    with torch.no_grad():\n",
    "        out, _ = model(data.x, data.edge_index)  # Perform a forward pass.\n",
    "        loss = criterion(out[data.test_mask], data.y[data.test_mask])\n",
    "        \n",
    "        pred = out.argmax(dim=1)  # Get the predicted labels by selecting the class with the highest probability.\n",
    "        # Calculate accuracy\n",
    "        correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "        total = data.test_mask.sum().item()\n",
    "        accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "        \n",
    "    \n",
    "    \n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_acc_hist = []\n",
    "test_acc_hist = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    train_loss, train_acc = train(data, epoch)\n",
    "    train_loss_history.append(train_loss.detach().numpy())\n",
    "    train_acc_hist.append(train_acc)\n",
    "    \n",
    "    test_loss, test_acc = test(data, epoch)\n",
    "    test_loss_history.append(loss.detach().numpy())\n",
    "    test_acc_hist.append(test_acc)\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        print(f\"\"\"Epoch: {epoch}, \n",
    "              Training Loss: {train_loss}, Training Accuracy: {train_acc}\n",
    "              Test Loss: {test_loss}, Test Accuracy: {test_acc} \n",
    "              \"\"\")#, Test Loss: {test_loss}')\n",
    "    \n",
    "    # \n",
    "        \n",
    "# clear_output(wait=True)\n",
    "plt.plot(epochs, train_loss_history, label='Training Loss')\n",
    "plt.plot(epochs, test_loss_history, label='Testing Loss')\n",
    "plt.plot(epochs, train_acc_hist, label='Training Accuracy')\n",
    "plt.plot(epochs, test_acc_hist, label='Testing Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training and Testing Metrics')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "    \n",
    "    # test_loss = test(data)\n",
    "    # print(f'Epoch: {epoch}, Loss: {loss}')#, Test Loss: {test_loss}')\n",
    "    # Plotting the training loss\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def test(model, device):\n",
    "#     evaluator = Evaluator(name=target_dataset)\n",
    "#     model.eval()\n",
    "#     out, var = model.inference(total_loader, device)\n",
    "#     y_true = data.y.cpu()\n",
    "#     y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "#     train_acc = evaluator.eval({\n",
    "#         'y_true': y_true[split_idx['train']],\n",
    "#         'y_pred': y_pred[split_idx['train']],\n",
    "#     })['acc']\n",
    "#     val_acc = evaluator.eval({\n",
    "#         'y_true': y_true[split_idx['valid']],\n",
    "#         'y_pred': y_pred[split_idx['valid']],\n",
    "#     })['acc']\n",
    "#     test_acc = evaluator.eval({\n",
    "#         'y_true': y_true[split_idx['test']],\n",
    "#         'y_pred': y_pred[split_idx['test']],\n",
    "#     })['acc']\n",
    "# return train_acc, val_acc, test_acc, torch.mean(torch.Tensor(var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
