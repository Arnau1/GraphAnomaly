{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0195ef-52db-415d-8c27-1d73052baa49",
   "metadata": {},
   "source": [
    "# Graph Anomaly Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d260f-cfe2-4bff-8371-f04ece167377",
   "metadata": {},
   "source": [
    "### Processing and analyzing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6611c5-9d2b-4804-be59-390630832b45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62935a85-ffc1-477d-9997-c6d4c0e34c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f0c835-44bb-4cde-8ad1-a8c0eec58f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files\n",
    "path = \"C:/Users/marti/Desktop/WAP/6e_semestre/SPII/GraphAnomaly/dades_marti/\"\n",
    "df_classes = pd.read_csv(path + \"elliptic_txs_classes.csv\") # Nodes' labels\n",
    "df_edges = pd.read_csv(path + \"elliptic_txs_edgelist.csv\") # Edges\n",
    "df_features = pd.read_csv(path + \"elliptic_txs_features.csv\", header=None) # Nodes' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce855918-d964-42f4-b9f7-c32d9189f415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change column names of df_features\n",
    "colNames1 = {'0': 'txId', 1: \"Time step\"}\n",
    "colNames2 = {str(ii+2): \"Local_feature_\" + str(ii+1) for ii in range(93)}\n",
    "colNames3 = {str(ii+95): \"Aggregate_feature_\" + str(ii+1) for ii in range(72)}\n",
    "\n",
    "colNames = dict(colNames1, **colNames2, **colNames3 )\n",
    "colNames = {int(jj): item_kk for jj,item_kk in colNames.items()}\n",
    "\n",
    "df_features = df_features.rename(columns=colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664158be-741a-4a8f-baf1-1b7e9dd5dcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1 belongs to illicit transactions, label 2 to licit transactions and label 3 to unknown transactions.\n",
      "\n",
      "Shape of classes (203769, 2)\n",
      "Shape of edges (234355, 2)\n",
      "Shape of features (203769, 167)\n"
     ]
    }
   ],
   "source": [
    "# Pass unknown to number 3\n",
    "df_classes.loc[df_classes['class'] == 'unknown', 'class'] = 3\n",
    "print('Label 1 belongs to illicit transactions, label 2 to licit transactions and label 3 to unknown transactions.\\n')\n",
    "print('Shape of classes', df_classes.shape)\n",
    "print('Shape of edges', df_edges.shape)\n",
    "print('Shape of features', df_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f12c7-602b-4f8c-b02c-5440f50ad329",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89baa3ce-89ae-48c5-8180-0837addd98be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         txId\n",
       "class        \n",
       "3      157205\n",
       "1        4545\n",
       "2       42019"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classes.groupby(['class']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9c6181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203769, 167), (203769, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape,df_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f378e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Aggregate_feature_64</th>\n",
       "      <th>Aggregate_feature_65</th>\n",
       "      <th>Aggregate_feature_66</th>\n",
       "      <th>Aggregate_feature_67</th>\n",
       "      <th>Aggregate_feature_68</th>\n",
       "      <th>Aggregate_feature_69</th>\n",
       "      <th>Aggregate_feature_70</th>\n",
       "      <th>Aggregate_feature_71</th>\n",
       "      <th>Aggregate_feature_72</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        txId  Time step  Local_feature_1  Local_feature_2  Local_feature_3  \\\n",
       "0  230425980          1        -0.171469        -0.184668        -1.201369   \n",
       "1    5530458          1        -0.171484        -0.184668        -1.201369   \n",
       "2  232022460          1        -0.172107        -0.184668        -1.201369   \n",
       "3  232438397          1         0.163054         1.963790        -0.646376   \n",
       "4  230460314          1         1.011523        -0.081127        -1.201369   \n",
       "\n",
       "   Local_feature_4  Local_feature_5  Local_feature_6  Local_feature_7  \\\n",
       "0        -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "1        -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "2        -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "3        12.409294        -0.063725         9.782742        12.414558   \n",
       "4         1.153668         0.333276         1.312656        -0.061584   \n",
       "\n",
       "   Local_feature_8  ...  Aggregate_feature_64  Aggregate_feature_65  \\\n",
       "0        -0.162097  ...             -0.600999              1.461330   \n",
       "1        -0.162112  ...              0.673103             -0.979074   \n",
       "2        -0.162749  ...              0.439728             -0.979074   \n",
       "3        -0.163645  ...             -0.613614              0.241128   \n",
       "4        -0.163523  ...             -0.400422              0.517257   \n",
       "\n",
       "   Aggregate_feature_66  Aggregate_feature_67  Aggregate_feature_68  \\\n",
       "0              1.461369              0.018279             -0.087490   \n",
       "1             -0.978556              0.018279             -0.087490   \n",
       "2             -0.978556             -0.098889             -0.106715   \n",
       "3              0.241406              1.072793              0.085530   \n",
       "4              0.579382              0.018279              0.277775   \n",
       "\n",
       "   Aggregate_feature_69  Aggregate_feature_70  Aggregate_feature_71  \\\n",
       "0             -0.131155             -0.097524             -0.120613   \n",
       "1             -0.131155             -0.097524             -0.120613   \n",
       "2             -0.131155             -0.183671             -0.120613   \n",
       "3             -0.131155              0.677799             -0.120613   \n",
       "4              0.326394              1.293750              0.178136   \n",
       "\n",
       "   Aggregate_feature_72  class  \n",
       "0             -0.119792      3  \n",
       "1             -0.119792      3  \n",
       "2             -0.119792      3  \n",
       "3             -0.119792      2  \n",
       "4              0.179117      3  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the DataFrames on the column 'source', assuming it's the same name in both DataFrames\n",
    "df_merged = pd.merge(df_features, df_classes, on='txId', how='left')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6a6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph = True\n",
    "if generate_graph:\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for _, row in df_features.iterrows():\n",
    "        # Extract node ID and attributes\n",
    "        node_id = row['txId']\n",
    "        node_attributes = row.drop('txId').to_dict()\n",
    "        # Add node to the graph with its attributes\n",
    "        G.add_node(node_id, **node_attributes)\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for _, row in df_edges.iterrows():\n",
    "        G.add_edge(row['txId1'], row['txId2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d087d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Save the graph as a pickle file\n",
    "with open(\"./dades_marti/elipticData_graph.pkl\", \"wb\") as f:\n",
    "    pkl.dump(G, f)\n",
    "\n",
    "\n",
    "# Specify the path to your pickle file\n",
    "pickle_file_path = path + 'elipticData_graph.pkl'\n",
    "\n",
    "# Open the pickle file in binary mode\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    # Load the data from the pickle file\n",
    "    G = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb18ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 203769\n",
      "Number of edges: 234355\n"
     ]
    }
   ],
   "source": [
    "# Get the number of nodes\n",
    "num_nodes = nx.number_of_nodes(G)\n",
    "\n",
    "# Get the number of edges\n",
    "num_edges = nx.number_of_edges(G)\n",
    "\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e19ee",
   "metadata": {},
   "source": [
    "Creating subgraphs for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acb7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the feature name and the desired feature value\n",
    "time_step = 'Time step'\n",
    "\n",
    "for value in  range(max(df_features['Time step'])):\n",
    "    # Create a list of nodes that have the desired value in the specified feature\n",
    "    desired_nodes = [node for node, data in G.nodes(data=True) if data.get(time_step) == value+1]\n",
    "    sub_G = G.subgraph(desired_nodes)\n",
    "\n",
    "    num_nodes = nx.number_of_nodes(sub_G)\n",
    "\n",
    "    # Get the number of edges\n",
    "    num_edges = nx.number_of_edges(sub_G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d41d04",
   "metadata": {},
   "source": [
    "### Adding common metrics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20314446",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m graus \u001b[38;5;241m=\u001b[39m [grau \u001b[38;5;28;01mfor\u001b[39;00m grau \u001b[38;5;129;01min\u001b[39;00m d_grau\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[0;32m      3\u001b[0m degree_centralities \u001b[38;5;241m=\u001b[39m [dc \u001b[38;5;28;01mfor\u001b[39;00m dc \u001b[38;5;129;01min\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mdegree_centrality(G)\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m----> 4\u001b[0m betweenness_centralities \u001b[38;5;241m=\u001b[39m [bc \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mbetweenness_centrality(G)\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[0;32m      5\u001b[0m eigenvector_centralities \u001b[38;5;241m=\u001b[39m [ec \u001b[38;5;28;01mfor\u001b[39;00m ec \u001b[38;5;129;01min\u001b[39;00m nx\u001b[38;5;241m.\u001b[39meigenvector_centrality(G)\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[0;32m      6\u001b[0m closeness_centralities \u001b[38;5;241m=\u001b[39m [cc \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(G)\u001b[38;5;241m.\u001b[39mkeys()]\n",
      "File \u001b[1;32mc:\\Users\\marti\\anaconda3\\envs\\graphanomaly\\Lib\\site-packages\\networkx\\classes\\backends.py:148\u001b[0m, in \u001b[0;36m_dispatch.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NetworkXNotImplemented(\n\u001b[0;32m    146\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not implemented by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m             )\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\marti\\anaconda3\\envs\\graphanomaly\\Lib\\site-packages\\networkx\\utils\\decorators.py:766\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 8:4\u001b[0m, in \u001b[0;36margmap_betweenness_centrality_5\u001b[1;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marti\\anaconda3\\envs\\graphanomaly\\Lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:131\u001b[0m, in \u001b[0;36mbetweenness_centrality\u001b[1;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# single source shortest paths\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use BFS\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_shortest_path_basic(G, s)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use Dijkstra's algorithm\u001b[39;00m\n\u001b[0;32m    133\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n",
      "File \u001b[1;32mc:\\Users\\marti\\anaconda3\\envs\\graphanomaly\\Lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:254\u001b[0m, in \u001b[0;36m_single_source_shortest_path_basic\u001b[1;34m(G, s)\u001b[0m\n\u001b[0;32m    252\u001b[0m P \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[1;32m--> 254\u001b[0m     P[v] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    255\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(G, \u001b[38;5;241m0.0\u001b[39m)  \u001b[38;5;66;03m# sigma[v]=0 for v in G\u001b[39;00m\n\u001b[0;32m    256\u001b[0m D \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Això triga com 10 minuts a correr!!!\n",
    "computar = True\n",
    "if computar:\n",
    "    d_grau = dict(G.degree())\n",
    "    graus = [grau for grau in d_grau.keys()]\n",
    "    print(\"Getting degrees - done!\")\n",
    "    degree_centralities = [dc for dc in nx.degree_centrality(G).keys()]\n",
    "    print(\"Getting degree centrality - done!\")\n",
    "    betweenness_centralities = [bc for bc in nx.betweenness_centrality(G).keys()]\n",
    "    print(\"Getting betweenness centrality - done!\")\n",
    "    eigenvector_centralities = [ec for ec in nx.eigenvector_centrality(G).keys()]\n",
    "    print(\"Getting eigenvector centrality - done!\")\n",
    "    closeness_centralities = [cc for cc in nx.closeness_centrality(G).keys()]\n",
    "    print(\"Getting closeness centrality - done!\")\n",
    "    clustering_coefficients = [cc for cc in nx.clustering(G).keys()]\n",
    "    print(\"Getting the clustering coefficient - done!\")\n",
    "\n",
    "    df_extended = df_merged.copy()\n",
    "    df_extended['degree'] = graus\n",
    "    df_extended['degree_centrality'] = degree_centralities\n",
    "    df_extended['betweenness_centrality'] = betweenness_centralities\n",
    "    df_extended['eigenvector_centrality'] = eigenvector_centralities\n",
    "    df_extended['closeness_centrality'] = closeness_centralities\n",
    "    df_extended['clustering_coefficient'] = clustering_coefficients\n",
    "    print(\"All done!\")\n",
    "\n",
    "    # Modify this to your \n",
    "    df_extended.to_csv('./dades_marti/extended.csv')\n",
    "\n",
    "else:\n",
    "    df_extended = pd.read_csv('./dades_marti/extended.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0b353",
   "metadata": {},
   "source": [
    "### Logistic regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8343f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79108cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: 0.9985460497241709\n",
      "Data reduction, from shape (203769, 166) to (203769, 100)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_pca = df_extended.drop(columns=['txid', 'timestep', 'class'])\n",
    "scaled_data = scaler.fit_transform(df_pca)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=100)  # You can choose the number of components you want to keep\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create a DataFrame for the principal components\n",
    "columns = [f\"PC{i+1}\" for i in range(principal_components.shape[1])]\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=columns)\n",
    "\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = explained_variance_ratio.sum()\n",
    "\n",
    "print(f\"Explained variance ratio: {cumulative_variance_ratio}\")\n",
    "print(f\"Data reduction, from shape {df_pca.shape} to {principal_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40118a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd1eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35df5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bbc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7fee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75251e96",
   "metadata": {},
   "source": [
    "### Trying node embeddings with node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a671595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from node2vec import Node2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5071998",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m G\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marti\\anaconda3\\envs\\graphanomaly\\Lib\\site-packages\\networkx\\classes\\reportviews.py:194\u001b[0m, in \u001b[0;36mNodeView.__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXError(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support slicing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry list(G.nodes)[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m     )\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes[n]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "G.nodes[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382bdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
