{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node identifier: Machine Learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test set\n",
    "path = 'C:/Users/User/Desktop/Assignatures/Synthesis project/GraphAnomaly/dades_arnau/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use balanced split\n",
    "with open(path + 'balanced_train.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "with open(path + 'balanced_test.pkl', 'rb') as f:\n",
    "    test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "train_set = train_set.loc[train_set['class'].isin([0, 1])]\n",
    "y_train = train_set['class']\n",
    "X_train = train_set.drop(columns=['class'])\n",
    "\n",
    "# y_test = test_set.loc[test_set['class'].isin([0, 1])]['class']\n",
    "# X_test = test_set.loc[test_set['class'].isin([0, 1])].drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         1\n",
       "7         0\n",
       "12        1\n",
       "13        1\n",
       "17        1\n",
       "         ..\n",
       "160587    1\n",
       "160591    1\n",
       "160596    1\n",
       "160597    1\n",
       "160601    1\n",
       "Name: class, Length: 37326, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dimensionality reduction\n",
    "# def apply_PCA(ncomponents):\n",
    "#     # Standardize the features\n",
    "#     scaler = StandardScaler()\n",
    "#     df_pca = train_set.drop(columns=['class'])\n",
    "#     scaled_data = scaler.fit_transform(df_pca)\n",
    "\n",
    "#     # Apply PCA\n",
    "#     pca = PCA(n_components=ncomponents)  # You can choose the number of components you want to keep\n",
    "#     principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "#     # Create a DataFrame for the principal components\n",
    "#     columns = [f\"PC{i+1}\" for i in range(principal_components.shape[1])]\n",
    "#     principal_df = pd.DataFrame(data=principal_components, columns=columns)\n",
    "\n",
    "\n",
    "#     explained_variance_ratio = pca.explained_variance_ratio_\n",
    "#     cumulative_variance_ratio = explained_variance_ratio.sum()\n",
    "\n",
    "#     print(f\"\\nExplained variance ratio: {cumulative_variance_ratio}\")\n",
    "#     print(f\"Data reduction, from shape {df_pca.shape} to {principal_df.shape}\")\n",
    "    \n",
    "#     # Add two columns to be able to apply ML models later on\n",
    "#     principal_df['node'] = df_pca.index\n",
    "#     principal_df['class'] = list(train_set['class'])\n",
    "    \n",
    "#     return principal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class machineLearning2:\n",
    "    def __init__(self, train_set, test_set):\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.metrics = pd.DataFrame(columns=[\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 score\"])\n",
    "        self.predictions = {}\n",
    "   \n",
    "\n",
    "    \n",
    "    def train_and_test(self, algorithm, display_conf_matrix=False):\n",
    "        X_train = self.train_set.loc[self.train_set['class'].isin([1, 2])].drop(columns=['class'])\n",
    "        y_train = self.train_set.loc[self.train_set['class'].isin([1, 2])]['class']\n",
    "        \n",
    "        X_test = self.test_set.loc[self.test_set['class'].isin([1, 2])].drop(columns=['class'])\n",
    "        y_test = self.test_set.loc[self.test_set['class'].isin([1, 2])]['class']\n",
    "        \n",
    "        print(f\"\\nTraining {algorithm}...\\n\")\n",
    "        try:\n",
    "            if algorithm == \"Logistic regression\":\n",
    "                model = LogisticRegression()\n",
    "                \n",
    "            elif algorithm == \"Random forest\":\n",
    "                model = RandomForestClassifier()\n",
    "                \n",
    "            elif algorithm == \"SVM\":\n",
    "                model = SVC()\n",
    "            \n",
    "            elif algorithm == \"Decision tree\":\n",
    "                model = DecisionTreeClassifier()\n",
    "            \n",
    "        except:\n",
    "            return \"Error! No machine learning model chosen.\"\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        self.predictions[algorithm] = y_pred\n",
    "        \n",
    "        print(f\"Testing {algorithm}...\\n\")\n",
    "        accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "        print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "        \n",
    "        precision = round(precision_score(y_test, y_pred, pos_label=1), 2)\n",
    "        print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "        \n",
    "        recall = round(recall_score(y_test, y_pred, pos_label=1), 2)\n",
    "        print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "        \n",
    "        f1 = round(f1_score(y_test, y_pred, pos_label=1),2)\n",
    "        print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n",
    "        \n",
    "        self.metrics.loc[len(self.metrics)] = [algorithm, accuracy, precision, recall, f1]\n",
    "        \n",
    "        if display_conf_matrix:\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[1, 2])\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ilicit', 'Licit'])\n",
    "            disp.plot()\n",
    "            plt.title(algorithm)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            # plt.figure(figsize=(8, 6))\n",
    "            # sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', \n",
    "            #             xticklabels=model.classes_, \n",
    "            #             yticklabels=model.classes_)\n",
    "            # plt.xlabel('Predicted Labels')\n",
    "            # plt.ylabel('True Labels')\n",
    "            # plt.title(f'Confusion Matrix for {algorithm}')\n",
    "            # plt.show()\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        return self.metrics\n",
    "    \n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return self.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1010\u001b[0m         X,\n\u001b[0;32m   1011\u001b[0m         y,\n\u001b[0;32m   1012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1013\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:294\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 294\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    295\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m ]:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Testing {model}...\\n\")\n",
    "accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "precision = round(precision_score(y_test, y_pred, pos_label=1), 2)\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "\n",
    "recall = round(recall_score(y_test, y_pred, pos_label=1), 2)\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "\n",
    "f1 = round(f1_score(y_test, y_pred, pos_label=1),2)\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ilicit', 'Licit'])\n",
    "disp.plot()\n",
    "plt.title(model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
